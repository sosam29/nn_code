dstree <- rpart(low ~ .-bwt, data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
dstree <- rpart(low ~ ., data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
dstree <- rpart(low ~ .-btw, data=train_df, method='class', cp=0.009)
dstree <- rpart(low ~ .-bwt, data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
View(test_df)
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.1)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.0001)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
predict_df <- predict(dstree, test_df, class='class')
t <-table(predictions=predict_df, test_df$low)
predict_df
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
predict_df <- predict(dstree, test_df, class='class')
dstree
dim(dstree)
library(pROC)
install.packages("pROC")
library(pROC)
install.packages("pROC")
library(pROC)
install.packages("pROC")
install.packages("pROC")
library("pROC", lib.loc="/anaconda3/lib/R/library")
library("rpart", lib.loc="/anaconda3/lib/R/library")
library("rpart.plot", lib.loc="/anaconda3/lib/R/library")
library(MASS)
df <- birthwt
cols <-c("lwt","race","smoke","ptl","ht","ui","ftv")
for (st in cols) {
df[,st]= as.factor(df[,st])
}
install.packages("caTools")
library(caTools)
ind <- sample.split(Y=df$low, SplitRatio = 0.8)
train_df <- df[ind,]
test_df <- df[!ind]
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.009)
summary(dstree)
prp(dstree)
prp(dstree, extra = 1)
library(pROC)
predict_df <- predict(dstree, test_df, class='class')
t <-table(predictions=predict_df, test_df$low)
predict_df
predict_df <- predict(dstree, test_df, type='class')
predict_df
t <-table(predictions=predict_df, test_df$low)
pred_acc = sum(diag(t))/sum(t)
pred_acc
predict_prob <- predict(dstree, test_df, type='prob')
predict_prob
t_auc <-auc(predictions=predict_prob[,2], test_df$low)
predict_prob
t_auc <-auc(predictions=predict_prob[,2], test_df$low)
t_auc <-auc(test_df$low, predict_prob[,1])
t_auc <-auc(test_df$low, predict_prob[,1])
plot(roc(test_df$low, predict_prob[,1]))
plot(roc(test_df$low, predict_prob[,0]))
plot(roc(test_df$low, predict_prob[,2]))
plot(roc(test_df$low, predict_prob[,1]))
plot(roc(test_df$low, predict_prob[,2]))
set.seed(123)
ind <- sample.split(Y=df$low, SplitRatio = 0.8)
train_df <- df[ind,]
test_df <- df[!ind]
dstree <- rpart(low ~ age+lwt+race+smoke, data=train_df, method='class', cp=0.009)
predict_class <- predict(dstree, test_df, type='class')
t <-table(predictions=predict_class, test_df$low)
pred_acc_class = sum(diag(t))/sum(t)
predict_prob <- predict(dstree, test_df, type='prob')
t_auc <-auc(test_df$low, predict_prob[,1])
plot(roc(test_df$low, predict_prob[,2]))
library(MASS)
library(randomForest)
rfNews()
?randomForest
set.seed(123)
df <-birthwt
cols <-c("low","race", "smoke","ptl","ftv","ht", "ui")
for (str in cols) {
df[,st]<-as.factor(df[,st])
}
cols <-c("low","race", "smoke","ptl","ftv","ht", "ui")
for (st in cols) {
df[,st]<-as.factor(df[,st])
}
library(caTools)
ind <-sample.split(Y= df$low, SplitRatio = 0.8)
df_train<- df[ind,]
df_test <- df[!ind,]
colnames(df_train)
RandomForestModel <- randomForest(low~,.-bwt, data= df_train, method="class", mtry=3)
RandomForestModel <- randomForest(low~.-bwt, data= df_train, method="class", mtry=3)
summary(RandomForestModel)
View(RandomForestModel)
PredictionWithClass <-predict(RandomForestModel, df_test, type ="class")
t<-table(PredictionWithClass,df_test$low)
t
conf_matrix <- sum(diag(t))/sum(t)
t
conf_matrix
RandomForestModel <- randomForest(low~.-bwt, data= df_train, method="class",
mtry=3, ntree=1000)
summary(RandomForestModel)
## Predictionwith Class
PredictionWithClass <-predict(RandomForestModel, df_test, type ="class")
t<-table(PredictionWithClass,df_test$low)
t
conf_matrix <- sum(diag(t))/sum(t)
conf_matrix
PredictionWithProb <-predict(RandomForestModel, df_test, type ="prob")
str(PredictionWithProb)
head(PredictionWithClass[,2])
head(PredictionWithClass,2)
auc<-auc(df_test$low, PredictionWithProb[,2])
plot(roc(df_test$low, PredictionWithProb[,2]))
install.packages("e1071")
setwd("~/Downloads/UDEMY_ML/Polynomial_Regression")
dataset <- read.csv('Position_Salaries.csv')
View(dataset)
View(df)
View(df)
X<- dataset[2]
dataset <- read.csv('Position_Salaries.csv')
X<- dataset[2]
View(X)
View(X)
y<- dataset[3]
View(y)
lin_reg <- lm.fit(X, y)
View(X)
View(X)
X<- dataset[2:3]
dataset<- dataset[2:3]
View(dataset)
X<- dataset[1]
y <- dataset[2]
View(X)
View(y)
lin_reg <- lm(formula = Salary~.,
summary(lin_reg)
lin_reg <- lm(formula = Salary~.,
data = dataset)
summary(lin_reg)
lin_reg <- lm(formula = Salary~.,
data = dataset)
summary(lin_reg)
dataset$Level2 <- dataset$Level^2
dataset$Level3 <- dataset$Level^3
lin_reg <- lm(formula = Salary~.,
data = dataset)
poly_reg <- lm(formula = Salary~.,
data = dataset)
summary(poly_reg)
library("ggplot2", lib.loc="/anaconda3/lib/R/library")
ggplot()+
geom_point(aex(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(poly_reg, newdata = dataset)), color='blue')+
ggtitle("Truth about salary") +
xlab("Level")+
ylab('Salary')
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(poly_reg, newdata = dataset)), color='blue')+
ggtitle("Truth about salary") +
xlab("Level")+
ylab('Salary')
guess <- predict(poly_reg, newdata = 6.5)
y_pred <- predict(poly_reg, data.frame(6.5))
y_pred <- predict(poly_reg, data.frame(Level=6.5))
y_pred <- predict(poly_reg, data.frame(Level=6.5, Level2=42.25, Level3=274.625))
y_pred <- predict(poly_reg, data.frame(Level=6.5, Level2=6.5^2, Level3=6.5^3))
setwd("~/Downloads/UDEMY_ML/SVR")
detach("package:ggplot2", unload=TRUE)
library("e1071", lib.loc="/anaconda3/lib/R/library")
library(e1071)
regressor <- svm(formula=Salary~.,data= dataset , type='eps-regression')
dataset <- read.csv('Position_Salaries.csv')
dataset<- dataset[2:3]
X<- dataset[1]
y <- dataset[2]
library(e1071)
regressor <- svm(formula=Salary~.,data= dataset , type='eps-regression')
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary") +
xlab("Level")+
ylab('Salary')
library("ggplot2", lib.loc="/anaconda3/lib/R/library")
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
setwd("~/Downloads/UDEMY_ML/SVR")
dataset <- read.csv('Position_Salaries.csv')
# create varible to get the columns of interest
dataset<- dataset[2:3]
X<- dataset[1]
y <- dataset[2]
dataset <- read.csv('Position_Salaries.csv')
# create varible to get the columns of interest
dataset<- dataset[2:3]
X<- dataset[1]
y <- dataset[2]
library(sparklyr)
regressor <- ml_decision_tree_regressor(formula=Salary~.,data= dataset , type='regression')
library(rpart)
library(rpart)
regressor <- rpart(formula=Salary~.,data= dataset , type='regression')
regressor <- rpart(formula=Salary~.,data= dataset )
summary(regressor)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary DecisionTree") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
regressor <- rpart(formula=Salary~.,data= dataset, control = rpart.control(minsplit = 1L) )
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary DecisionTree") +
xlab("Level")+
ylab('Salary')
regressor <- rpart(formula=Salary~.,data= dataset, control = rpart.control(minsplit = 10L) )
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary DecisionTree") +
xlab("Level")+
ylab('Salary')
regressor <- rpart(formula=Salary~.,data= dataset, control = rpart.control(minsplit = 0.5L) )
regressor <- rpart(formula=Salary~.,data= dataset, control = rpart.control(minsplit = 1L) )
ggtitle("Truth about salary DecisionTree") +
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary DecisionTree") +
xlab("Level")+
ylab('Salary')
regressor <- rpart(formula=Salary~.,data= dataset, control = rpart.control(minsplit = 1L) )
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary DecisionTree") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
X_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= X_grid, y = predict(regressor, newdata = data.frame(X_grid))), color='blue')+
ggtitle("Truth about High resolution DecisionTree") +
xlab("Level")+
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= X_grid, y = predict(regressor, newdata = data.frame(Level=X_grid))), color='blue')+
ggtitle("Truth about High resolution DecisionTree") +
xlab("Level")+
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= X_grid, y = predict(regressor, newdata = data.frame(Level=X_grid))), color='blue')+
ggtitle("Truth about High resolution DecisionTree") +
xlab("Level")+
ylab('Salary')
setwd("~/Downloads/UDEMY_ML/Random_Forest_Regression")
library("randomForest", lib.loc="/anaconda3/lib/R/library")
library(randomForest)
dataset <- read.csv('Position_Salaries.csv')
dataset<- dataset[2:3]
X<- dataset[1]
y <- dataset[2]
library(randomForest)
regressor <- randomForest(formula = Salary~.,
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='orange')+
ggtitle("Truth about salary Random Forest") +
xlab("Level")+
ylab('Salary')
regressor <- randomForest(formula = Salary~.,
data = dataset, ntree=100)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='orange')+
ggtitle("Truth about salary Random Forest") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary (Random Forest)") +
xlab("Level")+
ylab('Salary')
regressor <- randomForest(formula = Salary~.,
data = dataset, ntree=500)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary (Random Forest)") +
xlab("Level")+
ylab('Salary')
X_grid <- seq(min(dataset$Level), max(dataset$Level), 0.001)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= X_grid, y = predict(regressor, newdata = data.frame(Level=X_grid))), color='blue')+
ggtitle("Truth about salary (Random Forest)") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
regressor <- randomForest(formula = Salary~.,
data = dataset, ntree=1000)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= dataset$Level, y = predict(regressor, newdata = dataset)), color='blue')+
ggtitle("Truth about salary (Random Forest)") +
xlab("Level")+
ylab('Salary')
X_grid <- seq(min(dataset$Level), max(dataset$Level), 0.001)
ggplot()+
geom_point(aes(x = dataset$Level, y=dataset$Salary), color='red') +
geom_line(aes(x= X_grid, y = predict(regressor, newdata = data.frame(Level=X_grid))), color='blue')+
ggtitle("Truth about salary (Random Forest)") +
xlab("Level")+
ylab('Salary')
y_pred <- predict(regressor, data.frame(Level=6.5))
setwd("~/Downloads/UDEMY_ML/Logistic_Regression")
dataset <- read.csv('Social_Network_ads.csv')
View(dataset)
dataset<- dataset[3:6]
dataset<- dataset[3:5]
View(dataset)
X<- dataset[1:2]
y <- dataset[3]
View(y)
View(X)
library(caTools)
set.seed(123)
split <= sample.split(dataset= dataset, SplitRatio = 0.25)
split <= sample.split(dataset, SplitRatio = 0.25)
split <= sample.split(dataset$Purchased, SplitRatio = 0.25)
View(dataset)
split <- sample.split(dataset$Purchased, SplitRatio = 0.25)
trainingset <- subset(dataset, split= T)
testset <- subset(dataset, split =F)
trainingset <- subset(dataset, split== T)
testset <- subset(dataset, split ==F)
View(trainingset)
View(trainingset)
trainingset[,1:2] <- scale(trainingset[,1:2])
View(trainingset)
View(trainingset)
View(testset)
testset[,1:2] <- scale(testset[,1:2])
View(testset)
classifier = glm(formula = Purchased~., data = trainingset, family = binomial)
View(classifier)
pred_response <- predict(classifier, type = 'response', newdata = testset[-3])
y_pred <- ifelse(pred_response>0.5, 1, 0)
View(trainingset)
source('~/Downloads/UDEMY_ML/Logistic_Regression/my_logistic_regression.R', echo=TRUE)
cm= table(testset[3], y_pred)
cm= table(testset[,3], y_pred)
install.packages("ElemStatLearn")
library(ElemStatLearn)
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Plot of Age and estimated Salary",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = rangel(X2))
coutour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "spinggreen3", "tomoto"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Plot of Age and estimated Salary",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = range(X2))
coutour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "spinggreen3", "tomoto"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Plot of Age and estimated Salary",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = range(X2))
coutour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "spinggreen3", "tomato"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Plot of Age and estimated Salary",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "spinggreen3", "tomato"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Logistic Regression(training set)",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "springgreen3", "tomato"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
set = trainingset
X1 = seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier,type='response', newdata = set)
y_grid = ifelse(prob_set >0.5, 1, 0)
plot(set[, -3],
main = "Logistic Regression(training set)",
xlab = "Age",
ylab = "Esimated Salary",
xlim = range(X1),
ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=T)
points(grid_set, pch='.', col=ifelse(y_grid==1, "springgreen3", "tomato"))
points(set, pch=21, bg=ifelse(set[,3]==1, "green4", "red3"))
X1 = seq(min(set[,1])-1, max(set[,1])+1, step=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, step=0.01)
X1 = seq(min(set[,1])-1, max(set[,1])+1, steps=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, steps=0.01)
X1 = seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2 = seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
View(set)
source('~/Downloads/UDEMY_ML/Logistic_Regression/logistic_regression.R', echo=TRUE)
source('~/Downloads/UDEMY_ML/Logistic_Regression/logistic_regression.R', echo=TRUE)
setwd("~/Downloads/UDEMY_ML/SVM")
detach("package:ggplot2", unload=TRUE)
library("ggplot2", lib.loc="/anaconda3/lib/R/library")
install.packages("caret")
library("caret", lib.loc="/anaconda3/lib/R/library")
